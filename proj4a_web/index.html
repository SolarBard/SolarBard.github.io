<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Morphing Project Write-Up</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }
        .container {
            width: 95%;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3 {
            color: #005f99;
        }
        p {
            margin-bottom: 20px;
        }
        code {
            background-color: #f1f1f1;
            padding: 2px 6px;
            border-radius: 4px;
        }
        ul {
            margin-bottom: 20px;
            padding-left: 20px;
        }
        .image-container {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        figure {
            text-align: center;
        }
        .image-container img {
            width: 500px; /* Set fixed width to make both images equal */
            height: auto;
            border: 2px solid #ddd;
            border-radius: 8px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
        }
        figcaption {
            margin-top: 10px;
            font-style: italic;
            color: #555;
        }
    </style>
</head>
<body>
        <h1>Project 4: Image Warping and Mosaicing</h1>
        <h3 style="color: #333;">By Dmytro Krukovskyi</h3>
        <h2>Recovering Homographies</h2>
        <p>To warp images we need to find 3x3 matrix H with 8 degrees of freedom. For each corresponding pair of 
            points (x,y) and (x', y'), we can represent them in homogeneous coordinates and get the following:
        </p>  
        <div class="image-container">
            <img src="img/homog1.png" alt="">
        </div>
        <p>To recover the homography, we need at least four corresponding points between the two images. 
            Each correspondence provides two equations, and with four correspondences, we get a system of 8 equations—sufficient to solve for the 8 unknowns in H. 
            However, because such a system is sensitive to noise, using more than four correspondences is recommended. 
            This creates an overdetermined system that can be solved with least-squares.
            </p>
            <div class="image-container">
                <img src="img/homog2.png" alt="">
            </div>
        <h2>Warping the images</h2>
        <p>
            With the homography matrix H recovered, we can now warp an image to align it with a reference image. 
            This is achieved using inverse warping, which ensures that every pixel in the output image receives a valid value by mapping its position 
            back to the input image. 
        </p>
        <h2>Image rectification</h2>
        <p>Image rectification is a process that uses a homography to adjust an image such 
            that a selected object appears rectangular, correcting for perspective distortion. 
            This is particularly useful for scenes containing paintings, posters, or tiles, where known geometric 
            shapes can serve as reference objects.
        </p>
        <p>To perform rectification, we use a single input image and define correspondences between points in the image and a desired rectangular shape. 
            For example, if the photo contains a poster, you can manually select its four corners using a mouse-click interface and store their coordinates. 
            Next, you define the corresponding points as the corners of a square</p>
        <div class="image-container">
            <img src="img/projected_orig.png" alt="">
        </div>
        <div class="image-container">
            <img src="img/projected.png" alt="">
        </div>
        <div class="image-container">
            <img src="img/ex2.png" alt="">
        </div>
        <div class="image-container">
            <img src="img/ex_res.png" alt="">
        </div>
        <h2>Blend the images into a mosaic</h2>
        <p>To create the panorama from multiple images, the following procedure was followed:
        </p>
        <ol>
            <li>Create a Large Output Image and Predict the Mosaic Size</li>
            <p>The size of the output mosaic was determined by transforming the corners of both input images using the computed homography. 
                This allowed to predict the bounding box that would contain both images. A translation matrix was applied to ensure both 
                images fit into the shared coordinate space of the output canvas.
            </p>
            <li>Warp the Images Using Inverse Warping</li>
            <p>This approach ensures that each pixel in the output canvas receives a value by mapping back to the original images,
                 avoiding holes and gaps. The images were warped using: warpImage() function from the previous part.
            </p>

            <li>Blend images together</li>
            
          </ol>
          <div class="image-container">
            <img src="img/scu/left copy.JPG" alt="">
            <img src="img/scu/mid copy.JPG" alt="">
        </div>
        <div class="image-container">
            <img src="img/scu/new_panorama.jpg" alt="">
        </div>
        <p>To hide the seam i applied blending. I used laplacian stack that I implemented in project two. 
            I got the best results when using 3 levels laplacian stack.

        </p>
            <div class="image-container">
                <img src="img/scu/blend_panorama.jpg" alt="">
            </div>
            <p>Even though my approach is not ideal as there are some artifacts at thebottom of the image. 
                In general I am satisfied with the result. Here are some more examples.</p>
                <div class="image-container">
                    <img src="img/night/left.JPG" alt="">
                    <img src="img/night/mid.JPG" alt="">
                </div>  
                <div class="image-container">
                    <img src="img/night copy/new_panorama.jpg" alt="">
                </div>  
                <div class="image-container">
                    <img src="img/view/left.JPG" alt="">
                    <img src="img/view/mid.JPG" alt="">
                </div>  
                <div class="image-container">
                    <img src="img/view copy/new_panorama.jpg" alt="">
                </div>
        <h2>Part B: Feature Matching for Autostitching</h2>  
        <p>In part A I manually selected corresponding points. In this part I implemented automatic detection of such points by replicating 
            “Multi-Image Matching using Multi-Scale Oriented Patches” by Brown et al paper.  The main features that are implemented are the following.</p>
            <ol>
                <li>Detecting corner features in an image using Harris detector</li>
                <li>Extracting a Feature Descriptor for each feature point</li>
                <li>Use a robust method (RANSAC) to compute a homography</li>
                <li> Produce mosaic</li>
              </ol>
              <h2>Detecting Corner features</h2>
              <p>I used Harris detector. The Harris feature detector is an algorithm used in computer vision to identify corners or 
                interest points in an image. It calculates a corner response function based on the local variations of image intensity, 
                identifying points where there is significant change in multiple directions, making them ideal for tracking or matching 
                between images. I limited number of points to 10 thousand.
              </p>
              <img src="img/harris_corners_ex.png" alt="">
              <h2>Adaptive Non-Maxmimal Suppression</h2>
              <p>Using Adaptive Non-Maximal Suppression (ANMS) allows for reducing the number of detected corners while ensuring that the 
                points are evenly distributed across the image. This approach is particularly useful in maintaining spatial coverage. 
                After experimentation, I decided to retain 1000 
                points as a final selection, striking a balance between computational efficiency and sufficient feature density. 
                Below is the formula applied, as derived from the original paper, to achieve this selection and spacing of feature points.
              </p>
              <img src="img/anms.png" alt="">
              <img src="img/after_anms.png" alt="">
              <h2>Feature Descriptors</h2>
              <p>To effectively match feature points across images, it's essential to capture more information than a single pixel. 
                Therefore, feature descriptors are used to encapsulate the local image characteristics around each keypoint, ensuring 
                consistency across different views of the same scene. In this approach, a 40x40 pixel patch is extracted around each 
                detected feature point and then downsampled to an 8x8 grayscale patch. These patches are normalized and demeaned to enhance 
                robustness against lighting variations.
              </p>
              <img src="img/example_feature_detector.png" alt="">
                <h2>Feature matching</h2>
                <p>After extracting feature descriptors, I matched keypoints between image pairs using the Sum of Squared Differences (SSD) 
                    as the similarity measure. For each descriptor in the first image, SSD was calculated against all descriptors in the 
                    second image to find the closest matches. To ensure reliability, Lowe's ratio test was applied: the ratio of the smallest 
                    SSD to the second smallest SSD was computed, and only matches with a ratio below a set threshold (0.65) were retained. 
                    This approach filters out ambiguous matches, retaining only those that are distinctly better than the alternatives. 
                </p>           
                <img src="img/before_ransac.png" alt="">
                <h2>RANSAC</h2>
                <p>After establishing feature correspondences between images, 
                    some matches may be incorrect or outliers, which can adversely affect the accuracy of the homography matrix. 
                    To address this, I employed Random Sample Consensus (RANSAC), a robust algorithm that mitigates the influence of these 
                    outliers.
                    The 4-point RANSAC algorithm operates as follows:
                    </p>
                    <ol>
                        <li>Random Sampling: Select four random pairs of matched keypoints.</li>
                        <li>Homography Computation: Calculate the homography matrix H</li>
                        <li>Inlier Detection: Determine which keypoint pairs fit the homography well by measuring if the distance between the 
                            transformed points and their counterparts is below a threshold ϵ. I set ϵ = 1</li>
                        <li> Repeat the above steps for some number of iterations. I ran It for 6000 iterations</li>
                      </ol>
                      <img src="img/after_ransace.png" alt="">
                      <p>After I get homography matrix I apply warping from the part A and get the final image as a result.</p>
                      <div class="image-container">
                        <img src="img/night_ransac.png" alt="">
                    </div>
                    <div class="image-container">
                        <img src="img/view_ransac.jpg" alt="">
                    </div>
                    <div class="image-container">
                        <img src="img/scu_ransac.jpg" alt="">
                    </div>
            <h2>Final Remarks</h2>
            <p>The project was very interesting especially the B part. I think I should have spent more time on the blending images when stiching 
                panoramas, because on some pictures seams at the bottom are visible. Also, adding some kind of color normalization will really make
                a difference, then the final image will look like panorama that the phone generates.
            </p>
    </body>
</html>
